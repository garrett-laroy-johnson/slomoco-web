<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Relational mixed reality sculptures</title>
  </head>

  <body>
    <article id="b4c34f6b-ef24-4d75-80a9-67da44b709f3" class="page sans">
      <header>
        <h1 class="page-title">Relational mixed reality sculptures</h1>
      </header>
      <div class="page-body">
        <p id="4ceff56b-9f70-419f-8503-c38c69e2d92c" class="">
          In this choreographic intervention, the performers move and dance
          together with relational mixed reality sculptures containing two
          motion-driven digital layers: the first is sound-reactive and the
          second is composed of augmented reality animations.
        </p>
        <figure id="7170b2a6-bff6-4c70-afbc-53bbaa1231d8" class="image">
          <img style="width: 384px" src="/img/firebird7.gif" />
          <figcaption>
            Movement explorations with the first sculptural prototype
          </figcaption>
        </figure>
        <p id="3324f2a8-3f80-4f7d-b4a6-d3b23b510ca6" class="">
          The sculptures are in a prototyping phase and work as big toys that
          expand the range of possible gestures and body movements while a human
          is interacting with a cellphone through sonic stimulation. The
          cellphone of each performer is attached to the sculpture and connected
          via BlueTooth to a portable speaker attached to the sculpture or the
          performer&#x27;s body. This system generates a sound-reactive
          vibratory landscape, allowing the performer to control the
          performance&#x27;s sound instead of only reacting to it.
        </p>
        <p id="3f2daa06-a8cc-4f90-83cb-8c54a1aa173a" class="">
          This is made possible through a javascript browser-based application
          built out of Apple&#x27;s Core Motion Framework for IOS devices that
          allows getting the cellphone&#x27;s orientation data coming from its
          IMU sensors (gyroscope and accelerometer events). The data is mapped
          into a frequency modulation system using
          <a href="https://p5js.org/reference/#/libraries/p5.sound"
            >p5.sound library</a
          >.
        </p>
        <p id="abd540ec-43b6-47dd-9772-0a6f9d47922a" class="">
          The sound landscape is the voice of the critter, the sound of their
          belly, the sound of the air moving around their body, the sound of the
          earth when their feet touch the ground. The sound of the fire inside
          of their belly. The sound of their memory.
        </p>
        <figure id="54427045-d81c-49e7-b37e-80bea8a98d0b">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/De43YA1q7zo"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen
          ></iframe>
          <figcaption>
            First open-air experiments. Brooklyn, Feb 2021
          </figcaption>
        </figure>
        <figure id="d91675df-1080-4888-8ea3-5d8db728fb2f">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/sI3dv6cOH7Y"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen
          ></iframe>
          <figcaption>Audience interaction view. Brooklyn, Feb 2021</figcaption>
        </figure>
        <p id="bfdb5a64-75b8-4499-bfa3-8fd41fd37c99" class="">
          The sculptures also have Image Targets to be tracked by an augmented
          reality application allowing the audience to watch the performance
          with a virtual layer composed of 3D motion-driven graphics. When the
          performers move the sculptures, the animations move with them. The
          target trackers are QR-Codes, allowing anyone who encounters the
          living-sculpture in a park or other public spaces to scan it and
          access a web-based AR experience.
        </p>
        <figure id="d71913e6-43b2-48d6-ba61-6a0c9fd8e82d" class="image">
          <img style="width: 937px" src="/img/firebird8.png" />
          <figcaption>
            Lua Girino, Viola He playing with a mixed reality sculpture at Fort
            Greene Park, April 2020
          </figcaption>
        </figure>
        <p id="005b5436-393e-4a83-a20c-6c697ba97ac5" class="">
          For the prototypes, I&#x27;m using AdobeAero and Spark AR Studio.
          Spark AR will allow a very accessible version for the Augmented
          Reality experience through Instagram or Facebook, but have limitations
          such as one target tracker per filter. Future plans include building
          an application for the work with Unity (Vuforia).
        </p>
        <figure id="4ff68037-5ced-4f3a-a4b1-6657c3101652">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/wXHpojDOgfs"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen
          ></iframe>
          <figcaption>
            Viola Leqi He and a more recent version of the AR sculpture working
            with the target-tracker. April, 2021
          </figcaption>
        </figure>
        <p id="7f6fa4a8-6b19-49fe-9b46-6fbde44a2bb0" class=""></p>
        <p id="451bf2fe-4f3a-4346-a8aa-c92467f636f0" class=""></p>
        <p id="da128257-8f27-4701-8ec0-8bda1bc6fef6" class=""></p>
        <p id="f9ad4691-384e-4dee-999d-c4ab1498507c" class=""></p>
        <p id="9cfc96cc-c677-4aa6-aa73-7fc54f4ff522" class=""></p>
        <p id="589162ec-d262-49c1-8937-81ecd4c1a7c8" class=""></p>
        <p id="ced0d5f4-9066-42be-ac00-4a9eebd07e4c" class=""></p>
        <p id="04412856-4da0-435b-9dd5-4f406f2a6a58" class=""></p>
      </div>
    </article>
  </body>
</html>
